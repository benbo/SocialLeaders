{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from calendar import IllegalMonthError,IllegalWeekdayError\n",
    "from dateutil.parser import parse\n",
    "from unidecode import unidecode\n",
    "\n",
    "def remove_excessive_ws(x):\n",
    "    if isinstance(x,str):\n",
    "        return ' '.join(x.split())\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def myunidecode(x):\n",
    "    if isinstance(x,str):\n",
    "        return unidecode(x)\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def remove_short(x):\n",
    "    if isinstance(x,str):\n",
    "        tmp = x.split()\n",
    "        return ' '.join([_x for _x in tmp if len(_x)>2])\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This deletion takes care of rows meant as separators that just contain the year\n",
      "number of rows before NA deletion: 366\n",
      "number of rows after NA deletion: 361\n"
     ]
    }
   ],
   "source": [
    "# load data of murders of social leaders \n",
    "lastrowdropped = False\n",
    "# load data of murders of social leaders\n",
    "data_social = pd.read_csv('Data/J_NHomicidiosLideresSocialesColombia2012-2017.csv', encoding='latin-1')\n",
    "\n",
    "# load homicides\n",
    "data_2012 = pd.read_csv('Data/Delito_Homicidios_2012.csv',encoding='latin-1')\n",
    "data_2013 = pd.read_csv('Data/Delito_Homicidios_2013.csv',encoding='latin-1')\n",
    "data_2014 = pd.read_csv('Data/Delito_Homicidios_2014.csv',encoding='latin-1')\n",
    "data_2015 = pd.read_csv('Data/Delito_Homicidios_2015.csv',encoding='latin-1')\n",
    "data_2016 = pd.read_csv('Data/Homicidios_2016.csv',encoding='utf8')\n",
    "data_2017 = pd.read_csv('Data/Homicidios_2017.csv',encoding='utf8')\n",
    "\n",
    "\n",
    "#remove rows that contains mostly nan\n",
    "print( 'This deletion takes care of rows meant as separators that just contain the year')\n",
    "print ('number of rows before NA deletion: {}'.format(data_social.shape[0]))\n",
    "data_social.dropna(axis=0,thresh=5,inplace=True)\n",
    "print( 'number of rows after NA deletion: {}'.format(data_social.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not lastrowdropped:\n",
    "    #last row contains total count. Drop this.\n",
    "    lastrowdropped = True\n",
    "    data_2012 = data_2012.drop(data_2012.index[-1])\n",
    "    data_2013 = data_2013.drop(data_2013.index[-1])\n",
    "    data_2014 = data_2014.drop(data_2014.index[-1])\n",
    "    data_2015 = data_2015.drop(data_2015.index[-1])\n",
    "    data_2016 = data_2016.drop(data_2016.index[-1])\n",
    "    data_2017 = data_2017.drop(data_2017.index[-1])\n",
    "    \n",
    "# Drop cantidad columns for now\n",
    "data_2012 = data_2012.drop('2012', axis=1)\n",
    "data_2013 = data_2013.drop('2013', axis=1)\n",
    "data_2014 = data_2014.drop('2014', axis=1)\n",
    "data_2015 = data_2015.drop('2015', axis=1)\n",
    "data_2016 = data_2016.drop('Cantidad', axis=1)\n",
    "data_2017 = data_2017.drop('Cantidad', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FECHA', 'DEPARTAMENTO', 'MUNICIPIO', 'DIA', 'HORA', 'BARRIO', 'ZONA',\n",
       "       'CLASE SITIO', 'ARMA EMPLEADA', 'MOVIL AGRESOR', 'MOVIL VICTIMA',\n",
       "       'EDAD', 'SEXO', 'ESTADO CIVIL', 'PAIS NACE', 'CLASE EMPLEADO',\n",
       "       'PROFESIONES', 'ESCOLARIDAD', 'CODIGO DANE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2012.columns = [x.strip() for x in data_2012.columns]\n",
    "data_2012.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify column names to match them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify column names so they match\n",
    "data_social.columns = [x.strip() for x in data_social.columns]\n",
    "data_2012.columns = [x.strip() for x in data_2012.columns]\n",
    "data_2013.columns = [x.strip() for x in data_2013.columns]\n",
    "data_2014.columns = [x.strip() for x in data_2014.columns]\n",
    "data_2015.columns = [x.strip() for x in data_2015.columns]\n",
    "data_2016.columns = [x.strip() for x in data_2016.columns]\n",
    "data_2017.columns = [x.strip() for x in data_2017.columns]\n",
    "data_2015.rename(columns={u'ARMA O MEDIO': u'ARMA EMPLEADA', \n",
    "                          u'CLASE DE SITIO': u'CLASE SITIO',u'GENERO ':u'SEXO', \n",
    "                         u'PROFESION':u'PROFESIONES', u'CODIGO DANE ':u'CODIGO DANE' }, inplace=True)\n",
    "data_2016.columns = map(myunidecode, data_2016.columns)\n",
    "data_2016.columns = map(myunidecode, data_2016.columns)\n",
    "data_2016.columns = map(str.upper, data_2016.columns)\n",
    "data_2016.rename(columns={u'CLASE DE SITIO': u'CLASE SITIO',u'PROFESION':u'PROFESIONES', \n",
    "                          u'CLASE DE EMPLEADO':u'CLASE EMPLEADO',u'PAIS DE NACIMIENTO':u'PAIS NACE' }, inplace=True)\n",
    "data_2017.columns = map(myunidecode, data_2017.columns)\n",
    "data_2017.columns = map(str.upper, data_2017.columns)\n",
    "data_2017.rename(columns={u'CLASE DE SITIO': u'CLASE SITIO',u'PROFESION':u'PROFESIONES', \n",
    "                          u'CLASE DE EMPLEADO':u'CLASE EMPLEADO',u'PAIS DE NACIMIENTO':u'PAIS NACE' }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate homicide datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ben/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_all = pd.concat((data_2012,data_2013,data_2014,data_2015,data_2016,data_2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove dates in the social leaders data that cannot be handled and are ambiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_social = list(data_social.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_deleted = [data_social[data_social[colnames_social[11]].str.contains(\"112012\")==True],\n",
    "                          data_social[data_social[colnames_social[11]].str.contains(\"16710/2011\")==True],\n",
    "                          data_social[data_social[colnames_social[11]].str.contains(\"REPORTE S/D\")==True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove/change row where date cannot be fixed\n",
    "data_social = data_social[data_social[colnames_social[11]].str.contains(\"112012\")!=True]\n",
    "data_social = data_social[data_social[colnames_social[11]].str.contains(\"16710/2011\")!=True]\n",
    "data_social = data_social[data_social[colnames_social[11]].str.contains(\"REPORTE S/D\")!=True]\n",
    "\n",
    "data_social[colnames_social[11]].replace(to_replace='15/022015', value='15/02/2015',inplace=True)\n",
    "data_social[colnames_social[11]].replace(to_replace='26/082016', value='26/08/2016',inplace=True)\n",
    "data_social[colnames_social[11]].replace(to_replace='07.04.203', value='07/04/2013',inplace=True)\n",
    "data_social[colnames_social[11]].replace(to_replace='17/04/214', value='17/04/2014',inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove accents to make NLP processing easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scan = [ u'SECCIONAL', u'NOMBRE VICTIMA', u'APELLIDO',\n",
    "       u'NOMBRES', u'CALIDAD DE LA VICTIMA', u'TIPO DE ORGANIZACIÓN',\n",
    "       u'ORGANIZACIÓN A LA QUE PERTENECE', u'NOMBRE DE LA ORGANIZACIÓN',\n",
    "       u'RANGO DENTRO DE LA ORGANIZACIÓN',\n",
    "       u'DEPARTAMENTO', u'MUNICIPIO', u'LUGAR ESPECIFICO', u'ARMA UTILIZADA',\n",
    "       u'INDICIADOS O IMPUTADOS', u'SITUACION JURIDICA IMPUTADOS',\n",
    "       u'ÓRDENES DE PROTECCIÓN', u'FASE PRCESAL']\n",
    "\n",
    "\n",
    "\n",
    "for colname in cols_to_scan:\n",
    "    data_social[colname] = data_social[colname].apply(myunidecode)\n",
    "    \n",
    "cols_to_scan = [u'ARMA EMPLEADA', u'BARRIO', u'CLASE EMPLEADO', u'CLASE SITIO',\n",
    "        u'DEPARTAMENTO', u'DIA',  u'ESCOLARIDAD',\n",
    "       u'ESTADO CIVIL', u'MOVIL AGRESOR', u'MOVIL VICTIMA',\n",
    "       u'MUNICIPIO', u'PAIS NACE', u'PROFESIONES', u'SEXO', u'ZONA']\n",
    "for colname in cols_to_scan:\n",
    "    data_all[colname] = data_all[colname].apply(myunidecode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read offical in municipality and department data to allow cleaning against official designations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_municipalities = pd.read_csv('Data/municipalities/Departamentos_y_municipios_de_Colombia.csv',encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_scan =  [u'REGION', u'DEPARTAMENTO', u'MUNICIPIO']\n",
    "for colname in cols_to_scan:\n",
    "    data_municipalities[colname] = data_municipalities[colname].apply(myunidecode)\n",
    "departamentos = [x.upper() for x in data_municipalities.DEPARTAMENTO.unique()]\n",
    "dep_to_id = {k:i for i,k in enumerate(sorted(departamentos))} \n",
    "id_to_dep = {i:k for k,i in dep_to_id.items()}\n",
    "municipios = [x.upper() for x in data_municipalities.MUNICIPIO.unique()]\n",
    "muni_to_id = {k:i for i,k in enumerate(sorted(municipios))} \n",
    "id_to_muni = {i:k for k,i in muni_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean MUNICIPIO and DEPARTAMENTO columns in social leaders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove excessive white spaces\n",
    "data_social['MUNICIPIO'] = data_social['MUNICIPIO'].apply(remove_excessive_ws)\n",
    "data_social['DEPARTAMENTO'] = data_social['DEPARTAMENTO'].apply(remove_excessive_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting individual mistakes\n",
    "idx = data_social[data_social.DEPARTAMENTO=='POR ESTA'].index[0]\n",
    "data_social.loc[idx,'DEPARTAMENTO']='GUAVIARE'\n",
    "idx = data_social[data_social.DEPARTAMENTO=='ARMA DE FUEGO'].index[0]\n",
    "data_social.loc[idx,'DEPARTAMENTO']='NARINO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual mapping for mistakes that cannot be rectified automatically\n",
    "to_replace_manual = {'TUMACO':'SAN ANDRES DE TUMACO',\n",
    "               'SAN JOSE DE APARTADO':'APARTADO',\n",
    "             'ISCUANDE':'SANTA BARBARA',\n",
    "            'PUERTO LEGUIZAMO':'LEGUIZAMO',\n",
    "             'LA HORMIGA':'VALLE DE GUAMEZ',\n",
    "             'SAN PEDRO DE LOS MILAGROS':'SAN PEDRO',\n",
    "             'EL BORDO':'PATIA',\n",
    "             'BARRIO COMUNEROS':'BOGOTA D.C.',\n",
    "             'TAMBO':'EL TAMBO',\n",
    "             'BUGA':'GUADALAJARA DE BUGA',\n",
    "             'COPEY':'EL COPEY',\n",
    "             'SAN VICENTE DE FERRER':'SAN VICENTE',\n",
    "             'LA GABARRA':'TIBU',\n",
    "             'ANTIOQUIA':'MEDELLIN'}\n",
    "for name,match in to_replace_manual.items():\n",
    "    data_social['MUNICIPIO'] \n",
    "    data_social.loc[data_social['MUNICIPIO']==name,'MUNICIPIO']=match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIRRALTA -> TIERRALTA\n",
      "BOGOTA -> BOGOTA D.C.\n",
      "MIRTANDA -> MIRANDA\n",
      "ALMAGER -> ALMAGUER\n",
      "TRUJULLO -> TRUJILLO\n",
      "JARIN -> JARDIN\n",
      "TAQUI -> TARQUI\n",
      "BARRANDUILLA -> BARRANQUILLA\n",
      "YOPAS -> YOPAL\n",
      "PIZARRO -> PIJAO\n",
      "CAPOALEGRE -> CAMPOALEGRE\n",
      "CASTILLO -> EL CASTILLO\n",
      "BARBACOS -> BARBACOAS\n",
      "VILLAGRAZON -> VILLAGARZON\n",
      "MITRASTO -> MISTRATO\n",
      "AGUA AZUL -> AGUAZUL\n",
      "CURMARAL -> CUMARAL\n",
      "DONCELLO -> EL DONCELLO\n",
      "CALAOTO -> CALOTO\n",
      "YACANQUIERE -> YACUANQUER\n",
      "CARMEN DE VIBORAL -> EL CARMEN DE VIBORAL\n",
      "MAGANGUE. -> MAGANGUE\n",
      "SAN CIVENTE DEL CAGUAN -> SAN VICENTE DEL CAGUAN\n",
      "MONTANITAS -> LA MONTANITA\n",
      "RUOSUCIO -> RIOSUCIO\n",
      "DOS QUEBRADAS -> DOSQUEBRADAS\n",
      "SAN JOSE DE GUAVIARE -> SAN JOSE DEL GUAVIARE\n",
      "CARTAGENA DEL CHIARA -> CARTAGENA DEL CHAIRA\n",
      "PIVIJAI -> PIVIJAY\n"
     ]
    }
   ],
   "source": [
    "#use difflib to automatically correct the rest of the municipios. \n",
    "# print all that is being replaced. \n",
    "import difflib\n",
    "to_replace_auto = {}\n",
    "for name in data_social['MUNICIPIO'].unique():\n",
    "    if not name in muni_to_id:\n",
    "        match = difflib.get_close_matches(name, municipios, n=1, cutoff=0.5)[0]\n",
    "        print( name,'->',match)\n",
    "        to_replace_auto[name]=match\n",
    "    \n",
    "for name,match in to_replace_auto.items():\n",
    "    data_social['MUNICIPIO'] \n",
    "    data_social.loc[data_social['MUNICIPIO']==name,'MUNICIPIO']=match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALLE DEL CUACA -> VALLE DEL CAUCA\n",
      "ANTIOAUIA -> ANTIOQUIA\n",
      "RISALDA -> RISARALDA\n",
      "CALLE DEL CAUCA -> VALLE DEL CAUCA\n",
      "NORTE DE SANTNADER -> NORTE DE SANTANDER\n",
      "RISARQALDA -> RISARALDA\n",
      "CUNDIMARCA -> CUNDINAMARCA\n",
      "BOGOTA -> BOGOTA D.C.\n",
      "VALLE DEL CAUDA -> VALLE DEL CAUCA\n",
      "RISARLADA -> RISARALDA\n",
      "ANTIOQ -> ANTIOQUIA\n"
     ]
    }
   ],
   "source": [
    "#use difflib to automatically correct the rest of the DEPARTAMENTOs. \n",
    "# print all that is being replaced. \n",
    "to_replace_auto = {}\n",
    "for name in data_social['DEPARTAMENTO'].unique():\n",
    "    if not name in dep_to_id:\n",
    "        match = difflib.get_close_matches(name, departamentos, n=1, cutoff=0.5)[0]\n",
    "        print (name,'->',match)\n",
    "        to_replace_auto[name]=match\n",
    "\n",
    "for name,match in to_replace_auto.items():\n",
    "    data_social['DEPARTAMENTO'] \n",
    "    data_social.loc[data_social['DEPARTAMENTO']==name,'DEPARTAMENTO']=match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_social.columns = map(myunidecode, data_social.columns)\n",
    "data_social.rename(columns={u'FECHA DE HECHOS          D/M/A.': u'Date',\n",
    "                            u'ARMA UTILIZADA': u'ARMA EMPLEADA'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning additional variables in Social Leaders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = u'CALIDAD DE LA VICTIMA'\n",
    "data_social[colname] = data_social[colname].apply(myunidecode)\n",
    "data_social[colname] = data_social[colname].apply(remove_excessive_ws)\n",
    "\n",
    "colname = u'NOMBRE DE LA ORGANIZACION'\n",
    "data_social[colname] = data_social[colname].apply(myunidecode)\n",
    "data_social[colname] = data_social[colname].apply(remove_excessive_ws)\n",
    "\n",
    "colname = u'TIPO DE ORGANIZACION'\n",
    "data_social[colname] = data_social[colname].apply(myunidecode)\n",
    "data_social[colname] = data_social[colname].apply(remove_excessive_ws)\n",
    "\n",
    "colname = u'ARMA EMPLEADA'\n",
    "data_social[colname] = data_social[colname].apply(myunidecode)\n",
    "data_social[colname] = data_social[colname].apply(remove_excessive_ws)\n",
    "data_social[colname] = data_social[colname].apply(remove_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean TIPO DE ORGANIZACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace_manual = {'LGTB':'LGTBI',\n",
    "               'COMUNITARIA':'COMUNAL',\n",
    "             'RESTITUCION DE TIERRAS':'RESTITUCION TIERRAS',\n",
    "            'RECLAMACION TIERRAS':'RESTITUCION TIERRAS',\n",
    "             'LGBT':'LGTBI',\n",
    "             'CAMPESINA':'CAMPESINO',\n",
    "                'COMUNITARIO ':'COMUNAL',\n",
    "                 'COMUNITARIO':'COMUNAL'}\n",
    "\n",
    "for name,match in to_replace_manual.items():\n",
    "    data_social[u'TIPO DE ORGANIZACION'] \n",
    "    data_social.loc[data_social[u'TIPO DE ORGANIZACION']==name,u'TIPO DE ORGANIZACION']=match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean ARMA EMPLEADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace_manual = {'ARMA EFUEGO':'ARMA FUEGO',\n",
    "               'ARAMA FUEGO':'ARMA FUEGO',\n",
    "             'ARNA FUEGO':'ARMA FUEGO',\n",
    "            'ARTMA FUEGO':'ARMA FUEGO',\n",
    "             'RMA FUEGO':'ARMA FUEGO',\n",
    "             'AGENAMA FUIGO':'ARMA FUEGO',\n",
    "                    'ARESAMA FUEGO':'ARMA FUEGO',\n",
    "                    'ARMA EFUEGO':'ARMA FUEGO',\n",
    "                    'ARNA FUEGR':'ARMA FUEGO',\n",
    "                    'ARMAS FUEGO':'ARMA FUEGO',\n",
    "                    'ARMA FUEGO.':'ARMA FUEGO',\n",
    "                    'ARMA CORTOPUNZANTE':'ARMA BLANCA',\n",
    "                    'ELEMENTO CONTUNDENTE':'OBJETO CONTUNDENTE',\n",
    "                    'POR ESTABLECER':'POR DETERMINAR',\n",
    "                    'CUASA MUERTE FUE POR AHORACMIENTO':'CUERDA/SOGA/CADENA',\n",
    "                    'OBJETO CONTUNDENTE VEHICULO':'VEHICULO'\n",
    "                    }\n",
    "for name,match in to_replace_manual.items():\n",
    "    data_social[u'ARMA EMPLEADA'] \n",
    "    data_social.loc[data_social[u'ARMA EMPLEADA']==name,u'ARMA EMPLEADA']=match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace and clean national homicides data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "municipios.append('SAN LUIS DE PALENQUE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replace_manual = {'VALLE':'VALLE DEL CAUCA',\n",
    "                     'GUAINAA':'GUAINIA',\n",
    "                     'NARIAO':'NARINO',\n",
    "                     'BOLAVAR':'BOLIVAR',\n",
    "                     'CARDOBA':'CORDOBA',\n",
    "                     'GUAJIRA':'LA GUAJIRA',\n",
    "                     'QUINDAO':'QUINDIO',\n",
    "                     'CHOCA':'CHOCO',\n",
    "                     'VAUPAS':'VAUPES',\n",
    "                     'GUAINAA':'GUAINIA',\n",
    "             'SAN ANDRES':'ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA',\n",
    "             'SAN ANDRAS':'ARCHIPIELAGO DE SAN ANDRES, PROVIDENCIA Y SANTA CATALINA'\n",
    "             }\n",
    "for name,match in to_replace_manual.items():\n",
    "    data_all['DEPARTAMENTO'] \n",
    "    data_all.loc[data_all['DEPARTAMENTO']==name,'DEPARTAMENTO']=match\n",
    "    \n",
    "to_replace_manual = {'BELAN':'BELEN',\n",
    "                 'MANA':'MANI',\n",
    "                 'TIBA':'TIBU',\n",
    "                 'PUERTO LEGUIZAMO':'LEGUIZAMO',\n",
    "                 'APAA':'APIA',\n",
    "                 'ATICA':'UTICA',\n",
    "                 'ACHA':'ACHI',\n",
    "                 'MANATA':'MANATI',\n",
    "                 'LLORA':'LLORO',\n",
    "                 'MITA (CT)':'MITU',\n",
    "                 'CHAA':'CHIA',\n",
    "                 'SOPA':'SOPO'}\n",
    "for name,match in to_replace_manual.items():\n",
    "    data_all['MUNICIPIO'] \n",
    "    data_all.loc[data_all['MUNICIPIO']==name,'MUNICIPIO']=match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "CIUDAD BOLAVAR -> CIUDAD BOLIVAR\n",
      "MEDELLAN (CT) -> MEDELLIN\n",
      "BARRANQUILLA (CT) -> BARRANQUILLA\n",
      "CARTAGENA (CT) -> CARTAGENA\n",
      "MANIZALES (CT) -> MANIZALES\n",
      "FLORENCIA (CT) -> FLORENCIA\n",
      "SAN JOSA DEL FRAGUA -> SAN JOSE DEL FRAGUA\n",
      "POPAYAN (CT) -> POPAYAN\n",
      "TIMBIQUA -> TIMBIQUI\n",
      "QUIBDA (CT) -> QUIBDO\n",
      "MONTERAA (CT) -> MONTERIA\n",
      "BOGOTA D.C. (CT) -> BOGOTA D.C.\n",
      "RIOHACHA (CT) -> RIOHACHA\n",
      "NEIVA (CT) -> NEIVA\n",
      "LEJANAAS -> LEJANIAS\n",
      "VILLAVICENCIO (CT) -> VILLAVICENCIO\n",
      "PASTO (CT) -> PASTO\n",
      "CACUTA (CT) -> CUCUTA\n",
      "PUERTO ASAS -> PUERTO ASIS\n",
      "BELAN DE UMBRAA -> BELEN DE UMBRIA\n",
      "BUCARAMANGA (CT) -> BUCARAMANGA\n",
      "IBAGUA (CT) -> IBAGUE\n",
      "CALI (CT) -> CALI\n",
      "JAMUNDA -> JAMUNDI\n",
      "CONVENCIAN -> CONVENCION\n",
      "ARMENIA (CT) -> ARMENIA\n",
      "QUINCHAA -> QUINCHIA\n",
      "SAN ZENAN -> SAN ZENON\n",
      "SANTA MARTA (CT) -> SANTA MARTA\n",
      "PEREIRA (CT) -> PEREIRA\n",
      "BOLAVAR -> BOLIVAR\n",
      "VALLEDUPAR (CT) -> VALLEDUPAR\n",
      "SAHAGAN -> SAHAGUN\n",
      "FUNDACIAN -> FUNDACION\n",
      "PIENDAMA -> PIENDAMO\n",
      "NAVITA -> NOVITA\n",
      "SAN JOSA DEL GUAVIARE (CT) -> SAN JOSE DEL GUAVIARE\n",
      "MOCOA (CT) -> MOCOA\n",
      "VALLE DEL GUAMUEZ -> VALLE DE GUAMEZ\n",
      "YOPAL (CT) -> YOPAL\n",
      "PUERTO LAPEZ -> PUERTO LOPEZ\n",
      "MONTELABANO -> MONTELIBANO\n",
      "ACACAAS -> ACACIAS\n",
      "LA UNIAN -> LA UNION\n",
      "EBAJICO -> EBEJICO\n",
      "PUERTO BERRAO -> PUERTO BERRIO\n",
      "CIANAGA -> CIENAGA\n",
      "CAPARRAPA -> CAPARRAPI\n",
      "BELAN DE LOS ANDAQUIES -> BELEN DE LOS ANDAQUIES\n",
      "ACANDA -> ACANDI\n",
      "CAJIBAO -> CAJIBIO\n",
      "APARTADA -> APARTADO\n",
      "TOLA VIEJO -> TOLU VIEJO\n",
      "PEAOL -> PENOL\n",
      "SAMPUAS -> SAMPUES\n",
      "MAGANGUA -> MAGANGUE\n",
      "DIBULLA -> DIBULA\n",
      "GIRAN -> GIRON\n",
      "RIOFRAO -> RIOFRIO\n",
      "GARZAN -> GARZON\n",
      "VISTAHERMOSA -> VISTA HERMOSA\n",
      "MISTRATA -> MISTRATO\n",
      "ANDALUCAA -> ANDALUCIA\n",
      "SINCELEJO (CT) -> SINCELEJO\n",
      "PUERTO CARREAO (CT) -> PUERTO CARRENO\n",
      "SANTAFA DE ANTIOQUIA -> SANTAFE DE ANTIOQUIA\n",
      "GUACARA -> GUACARI\n",
      "CHIGORODA -> CHIGORODO\n",
      "SUPAA -> SUPATA\n",
      "AGUSTAN CODAZZI -> AGUSTIN CODAZZI\n",
      "PUERTO LEGUAZAMO -> PUERTO GUZMAN\n",
      "LA MONTAAITA -> LA MONTANITA\n",
      "PULA -> PULI\n",
      "COLAN -> COLON\n",
      "YACOPA -> YACOPI\n",
      "ANORA -> ANORI\n",
      "SAN JOSA DE URA -> SAN JOSE DE URE\n",
      "ANGELAPOLIS -> ANGELOPOLIS\n",
      "EL CARMEN DE BOLAVAR -> EL CARMEN DE BOLIVAR\n",
      "TUNJA (CT) -> TUNJA\n",
      "OROCUA -> OROCUE\n",
      "ARIGUANA -> ARIGUANI\n",
      "PUEBLOVIEJO -> PUEBLO VIEJO\n",
      "VEGACHA -> VEGACHI\n",
      "TOGAA -> TOPAGA\n",
      "VILLAMARAA -> VILLAMARIA\n",
      "SALDAAA -> SALDANA\n",
      "PATAA -> PATIA\n",
      "CERETA -> CERETE\n",
      "TADA -> TADO\n",
      "VALPARAASO -> VALPARAISO\n",
      "SAN ANDRAS DE CUERQUAA -> SAN ANDRES DE CUERQUIA\n",
      "CHINA -> CHIA\n",
      "GANOVA -> GENOVA\n",
      "TAQUERRES -> TUQUERRES\n",
      "JAMBALA -> JAMBALO\n",
      "TIMBAO -> TIMBIO\n",
      "SAN ANDRAS (CT) -> SAN ANDRES\n",
      "MARAA LA BAJA -> MARIA LA BAJA\n",
      "SAN MARTAN DE LOBA -> SAN MARTIN DE LOBA\n",
      "OCAAA -> OCANA\n",
      "LABANO -> LIBANO\n",
      "BAHAA SOLANO -> BAHIA SOLANO\n",
      "HACARA -> HACARI\n",
      "SANTIAGO DE TOLA -> SANTIAGO DE TOLU\n",
      "CAAASGORDAS -> CANASGORDAS\n",
      "YONDA -> YONDO\n",
      "RAO DE ORO -> RIO DE ORO\n",
      "SAN MARTAN -> SAN MARTIN\n",
      "UNGUAA -> UNGUIA\n",
      "SAN AGUSTAN -> SAN AGUSTIN\n",
      "CONCEPCIAN -> CONCEPCION\n",
      "SAN LUIS DE PALENQUE -> SAN LUIS DE PALENQUE\n",
      "SAN JERANIMO -> SAN JERONIMO\n",
      "VILLAGARZAN -> VILLAGARZON\n",
      "SAN JOSA -> SAN JOSE\n",
      "CURITA -> CURITI\n",
      "YALA -> YALI\n",
      "SIPA -> SIPI\n",
      "TOPAIPA -> TOPAIPI\n",
      "DON MATAAS -> DON MATIAS\n",
      "SIBATA -> SIBATE\n",
      "LETICIA (CT) -> LETICIA\n",
      "GUACHENA -> GUACHETA\n",
      "NECOCLA -> NECOCLI\n",
      "SAN JOSA DEL PALMAR -> SAN JOSE DEL PALMAR\n",
      "EL TABLAN DE GAMEZ -> EL TABLON DE GOMEZ\n",
      "JURADA -> JURADO\n",
      "BRICEAO -> BRICENO\n",
      "GUATAPA -> GUATAPE\n",
      "GAEPSA -> GUEPSA\n",
      "RIOBLANCO -> RIO BLANCO\n",
      "NUNCHAA -> NUNCHIA\n",
      "CIANAGA DE ORO -> CIENAGA DE ORO\n",
      "SAN JOSA DE MIRANDA -> SAN JOSE DE MIRANDA\n",
      "VALEZ -> VELEZ\n",
      "BARRANCA DE UPAA -> BARRANCA DE UPIA\n",
      "MARIPA -> MARIPI\n",
      "ARAUCA (CT) -> ARAUCA\n",
      "JARDAN -> JORDAN\n",
      "TITIRIBA -> TITIRIBI\n",
      "REPELAN -> REPELON\n",
      "MAGAI -> MAGUI\n",
      "LARIDA -> LERIDA\n",
      "COVEAAS -> COVENAS\n",
      "CHOACHA -> CHOACHI\n",
      "LAPEZ -> LOPEZ\n",
      "GAMEZ PLATA -> GOMEZ PLATA\n",
      "TOTORA -> TOTORO\n",
      "YOLOMBA -> YOLOMBO\n",
      "CHACHAGAA -> CHACHAGUI\n",
      "POTOSA -> POTOSI\n",
      "CONTRATACIAN -> CONTRATACION\n",
      "CUATIVA -> CUITIVA\n",
      "SAN ANDRAS SOTAVENTO -> SAN ANDRES SOTAVENTO\n",
      "CURUMANA -> CURUMANI\n",
      "ELAAS -> ELIAS\n",
      "CHIBOLO -> CHIVOLO\n",
      "BAGADA -> BAGADO\n",
      "VALLE DE SAN JOSA -> VALLE DE SAN JOSE\n",
      "UNIAN PANAMERICANA -> UNION PANAMERICANA\n",
      "LOS CARDOBAS -> LOS CORDOBAS\n",
      "IMUAS -> IMUES\n",
      "CARACOLA -> CARACOLI\n",
      "RAO VIEJO -> RIO VIEJO\n",
      "EL CANTAN DEL SAN PABLO -> EL CANTON DEL SAN PABLO\n",
      "NECHA -> NECHI\n",
      "MOMPAS -> MOMPOS\n",
      "NARIAO -> NARINO\n",
      "SIMITA -> SIMITI\n",
      "NUQUA -> NUQUI\n",
      "EL RETAN -> EL RETEN\n",
      "VIANA -> VIANI\n",
      "BAJO BAUDA -> BAJO BAUDO\n",
      "CARDOBA -> CORDOBA\n",
      "SAN JUAN DE RAO SECO -> SAN JUAN DE RIO SECO\n",
      "EL PIAON -> EL PINON\n",
      "VIGAA DEL FUERTE -> VIGIA DEL FUERTE\n",
      "PAZ DE RAO -> PAZ DE RIO\n",
      "EL PLAYAN -> EL PLAYON\n",
      "NOROSA -> NOROSI\n",
      "RAO QUITO -> RIO QUITO\n",
      "MOAITOS -> MONITOS\n",
      "LA PEAA -> LA PENA\n",
      "SANTA MARAA -> SANTA MARTA\n",
      "JERICA -> JERICO\n",
      "EL PEAOL -> EL PENOL\n",
      "PURIFICACIAN -> PURIFICACION\n",
      "SAN JOAQUAN -> SAN JOAQUIN\n",
      "TUCHAN -> TUCHIN\n",
      "INARIDA (CT) -> INIRIDA\n",
      "SAN VICENTE DE CHUCURA -> SAN VICENTE DE CHUCURI\n",
      "EL PEAAN -> EL PENON\n",
      "USIACURA -> USIACURI\n",
      "PURASIMA -> PURISIMA\n",
      "CARCASA -> CARCASI\n",
      "SAN JOSA DE PARE -> SAN JOSE DE PARE\n",
      "VILLAPINZAN -> VILLAPINZON\n",
      "ALEJANDRAA -> ALEJANDRIA\n",
      "PURACA -> PURACE\n",
      "CHAGUANA -> CHAGUANI\n",
      "NEMOCAN -> NEMOCON\n",
      "RAMIRIQUA -> RAMIRIQUI\n",
      "ALTO BAUDA -> ALTO BAUDO\n",
      "SAN LUIS DE SINCA -> SAN LUIS DE SINCE\n",
      "JERUSALAN -> JERUSALEN\n",
      "SESQUILA -> SESQUILE\n",
      "QUAPAMA -> QUIPAMA\n",
      "EL CARMEN DE CHUCURA -> EL CARMEN DE CHUCURI\n",
      "JESAS MARAA -> JESUS MARIA\n",
      "DISTRACCIAN -> DISTRACCION\n",
      "ZIPACAN -> ZIPACON\n",
      "MEDIO BAUDA -> MEDIO BAUDO\n",
      "PIOJA -> PIOJO\n",
      "CAMBITA -> GAMBITA\n",
      "JUNAN -> JUNIN\n",
      "CHAQUIZA -> CHIQUIZA\n",
      "GUTIARREZ -> GUTIERREZ\n",
      "CARTEGUI -> CERTEGUI\n",
      "PUERTO RONDAN -> PUERTO RONDON\n",
      "RAO IRO -> RIO IRO\n",
      "VILLAGAMEZ -> VILLAGOMEZ\n",
      "TURMEQUA -> TURMEQUE\n",
      "GAICAN -> GUICAN\n",
      "SAN ANDRAS -> SAN ANDRES\n",
      "MEDELLIN (CT) -> MEDELLIN\n",
      "QUIBDO (CT) -> QUIBDO\n",
      "CUCUTA (CT) -> CUCUTA\n",
      "IBAGUE (CT) -> IBAGUE\n",
      "MONTERIA (CT) -> MONTERIA\n",
      "SAN ANDRES (CT) -> SAN ANDRES\n",
      "PUERTO CARRENO (CT) -> PUERTO CARRENO\n",
      "MITU (CT) -> MITU\n",
      "SAN JOSE DEL GUAVIARE (CT) -> SAN JOSE DEL GUAVIARE\n",
      "INIRIDA (CT) -> INIRIDA\n"
     ]
    }
   ],
   "source": [
    "#clear white space in name of attribute\n",
    "data_all.rename(columns={u'DEPARTAMENTO ': u'DEPARTAMENTO'}, inplace=True)\n",
    "\n",
    "#clear whitespaces and check the proposed mappings\n",
    "data_all[u'DEPARTAMENTO'] = data_all[u'DEPARTAMENTO'].apply(remove_excessive_ws)\n",
    "data_all[u'MUNICIPIO'] = data_all[u'MUNICIPIO'].apply(remove_excessive_ws)\n",
    "to_replace = {}\n",
    "for name in data_all[u'DEPARTAMENTO'].unique():\n",
    "    if not name in dep_to_id:\n",
    "        match = difflib.get_close_matches(name, departamentos, n=1, cutoff=0.5)[0]\n",
    "        print(name,'->',match) \n",
    "        to_replace[name]=match\n",
    "        \n",
    "print('-'*20) \n",
    "for name in data_all['MUNICIPIO'].unique():\n",
    "    if not name in muni_to_id:\n",
    "        result = difflib.get_close_matches(name, municipios, n=1, cutoff=0.5)\n",
    "        if result:\n",
    "            match = result[0]\n",
    "            print(name,'->',match) \n",
    "            to_replace[name]=match\n",
    "        else:\n",
    "            print(name,'!!!!!!!!! NO MATCH' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning arma empleada in homicide data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "colname = u'ARMA EMPLEADA'\n",
    "data_all[colname] = data_all[colname].apply(myunidecode)\n",
    "data_all[colname] = data_all[colname].apply(remove_excessive_ws)\n",
    "data_all[colname] = data_all[colname].apply(remove_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARMA FUEGO                      59643\n",
       "ARMA BLANCA                     16663\n",
       "CONTUNDENTES                     2601\n",
       "EXPLOSIVO                         621\n",
       "CUERDA/SOGA/CADENA                316\n",
       "BOLSA PLASTICA                    129\n",
       "REPORTADO                          87\n",
       "GASOLINA                           44\n",
       "SIN EMPLEO ARMAS                   36\n",
       "CINTAS/CINTURON                    27\n",
       "VENENO                             27\n",
       "ALMOHADA                           27\n",
       "SUSTANCIAS TOXICAS                 15\n",
       "COMBUSTIBLE                        15\n",
       "ARTEFACTO INCENDIARIO               9\n",
       "CINTAS                              8\n",
       "ACIDO                               4\n",
       "PRENDAS VESTIR                      4\n",
       "QUIMICOS                            3\n",
       "ESCOPOLAMINA                        2\n",
       "GASES                               1\n",
       "LIQUIDOS                            1\n",
       "JERINGA                             1\n",
       "ROCKET                              1\n",
       "MEDICAMENTOS                        1\n",
       "POLVORA(FUEGOS PIROTECNICOS)        1\n",
       "Name: ARMA EMPLEADA, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replace_manual = {'ARMA EFUEGO':'ARMA FUEGO',\n",
    "               'ARAMA FUEGO':'ARMA FUEGO',\n",
    "             'ARNA FUEGO':'ARMA FUEGO',\n",
    "            'ARTMA FUEGO':'ARMA FUEGO',\n",
    "             'RMA FUEGO':'ARMA FUEGO',\n",
    "             'AGENAMA FUIGO':'ARMA FUEGO',\n",
    "                    'ARESAMA FUEGO':'ARMA FUEGO',\n",
    "                    'ARMA EFUEGO':'ARMA FUEGO',\n",
    "                    'ARNA FUEGR':'ARMA FUEGO',\n",
    "                    'ARMAS FUEGO':'ARMA FUEGO',\n",
    "                    'ARMA FUEGO.':'ARMA FUEGO',\n",
    "                    'ARMA CORTOPUNZANTE':'ARMA BLANCA',\n",
    "                    'ELEMENTO CONTUNDENTE':'OBJETO CONTUNDENTE',\n",
    "                    'POR ESTABLECER':'POR DETERMINAR',\n",
    "                    'CUASA MUERTE FUE POR AHORACMIENTO':'AHORACMIENTO',\n",
    "                    'OBJETO CONTUNDENTE VEHICULO':'VEHICULO',\n",
    "                     'ARMA BLANCA CORTOPUNZANTE':'ARMA BLANCA',\n",
    "                     'CORTANTES':'ARMA BLANCA'  ,\n",
    "                     'PUNZANTES':'ARMA BLANCA'  ,\n",
    "                     'ARTEFACTO EXPLOSIVO/CARGA DINAMITA':'EXPLOSIVO',\n",
    "                     'MINA ANTIPERSONA': 'EXPLOSIVO',\n",
    "                     'GRANADA MANO':'EXPLOSIVO',\n",
    "                     'CILINDRO BOMBA':'EXPLOSIVO',\n",
    "                     'CASA BOMBA':'EXPLOSIVO',\n",
    "                     'MOTO BOMBA':'EXPLOSIVO',\n",
    "                     'GRANADA MORTERO':'EXPLOSIVO',\n",
    "                     'PAQUETE BOMBA':'EXPLOSIVO',\n",
    "                     'CARRO BOMBA':'EXPLOSIVO'\n",
    "                    }\n",
    "for name,match in to_replace_manual.items():\n",
    "    data_all[u'ARMA EMPLEADA'] \n",
    "    data_all.loc[data_all[u'ARMA EMPLEADA']==name,u'ARMA EMPLEADA']=match\n",
    "    \n",
    "data_all[u'ARMA EMPLEADA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify dates to proper format in both datasets (very slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert dates to proper format\n",
    "def convert_dates(dataset,datecol_idx):\n",
    "    for i in range(0,dataset.shape[0]):\n",
    "        try:\n",
    "            dataset.iloc[i,datecol_idx] = pd.Timestamp(parse(dataset.iloc[i,datecol_idx]))\n",
    "        except IllegalMonthError:\n",
    "            print(\"Month\") \n",
    "            print(i, dataset.iloc[i,datecol_idx]) \n",
    "        except IllegalWeekdayError:\n",
    "            print(\"Weekday\") \n",
    "            print(i, dataset.iloc[i,datecol_idx] ) \n",
    "        except ValueError:\n",
    "            print(\"Value\") \n",
    "            print(i, dataset.iloc[i,datecol_idx]) \n",
    "        except AttributeError:\n",
    "            print(\"Attribute\") \n",
    "            print(i, dataset.iloc[i,datecol_idx]) \n",
    "    return dataset\n",
    "\n",
    "data_social = convert_dates(data_social,11)\n",
    "data_all = convert_dates(data_all,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('Data'):\n",
    "    os.makedirs('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_social.to_pickle('Data/data_social.pkl')\n",
    "data_all.to_pickle('Data/data_all.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
